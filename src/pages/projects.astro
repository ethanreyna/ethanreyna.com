---
import Navbar from '../components/Navbar.astro';
import ProjectCard from '../components/projects/ProjectCard.astro';
import GradientLayout from '../layouts/GradientLayout.astro';
import Layout from '../layouts/Layout.astro';

type Image = {
	smallUrl: string;
	largeUrl: string;
}

const ProjectOneImages:Image[] = [{
	smallUrl: '/screenshot-report-generator-1.png',
	largeUrl: '/screenshot-report-generator-1.png',
},
{
	smallUrl: '/screenshot-report-generator-2.png',
	largeUrl: '/screenshot-report-generator-2.png',
},
{
	smallUrl: '/screenshot-report-generator-3.png',
	largeUrl: '/screenshot-report-generator-3.png',
},
{
	smallUrl: '/screenshot-report-generator-4.png',
	largeUrl: '/screenshot-report-generator-4.png',
}
]

const ProjectTwoImages:Image[] = [{
	smallUrl: '/screenshot-import-clients-1.png',
	largeUrl: '/screenshot-import-clients-1.png',
},
{
	smallUrl: '/screenshot-import-clients-2.png',
	largeUrl: '/screenshot-import-clients-2.png',
},
{
	smallUrl: '/screenshot-import-clients-3.png',
	largeUrl: '/screenshot-import-clients-3.png',
},
{
	smallUrl: '/screenshot-import-clients-4.png',
	largeUrl: '/screenshot-import-clients-4.png',
},
{
	smallUrl: '/screenshot-import-clients-5.png',
	largeUrl: '/screenshot-import-clients-5.png',
},
{
	smallUrl: '/screenshot-import-clients-6.png',
	largeUrl: '/screenshot-import-clients-6.png',
},
]

---

<Layout title="Ethan's Projects">
	<GradientLayout>
		<main>
			<header>
				<Navbar/>
			</header>
			<h1>here's some of my past projects</h1>
			<div class="subheader">
				hit that little arrow button to expand each project section to learn more about it!
			</div>
            <ProjectCard 
				project_name="Report Generator" 
				company="Trava" 
				description="Generates reports from vulnerability data."
				images={ProjectOneImages}
				sections={[
					{ 
						name: "Overview", 
						description: "This report generator is a project I worked on during my time at Trava. It allowed tenants to select different assessments they had run previously (assessments collected vulnerability data by running different scans on assets they chose) and applied them to a DOCX template that they also selected. During my time there, in the production environment, over 8000 reports were generated using this process. The generator was a vital piece of our product, as many tenants could easily use it to get Carrier Reports, which they could send to their providers and potentially get cheaper rates on their security insurance." 
					},
					{ 
						name: "Report Types", 
						description: "This system categorized reports into various \"Report Types\" stored in a Firebase collection. Each report type encompassed essential parameters for generating reports, including necessary inputs, labels, unique settings, and a link to the base docx template onto which the report would be generated. Throughout the \"Start Report\" process, this report type was transmitted to ensure that all requisite data was collected from the user." 
					},
					{ 
						name: "Start Report Process", 
						description: "The Start Report Process commenced after a report type had been chosen. Users proceeded by selecting required components for the report: a client, their assessments, surveys, or phishing campaigns. Upon selecting the necessary data, users could then opt for any additional settings before sending the report for generation." 
					},
					{ 
						name: "Report Generation", 
						description: "Once a report was submitted, the web app would send a request to the API with the report data in the body. The API then double-checked that all requirements for the report type were met and would subsequently send a request to our Report Generator service with that data. \nThe report generator would receive this call, retrieve the specified template from a GCS bucket, and also fetch all assessment/survey/phishing campaign data attached to the IDs sent from the initial report request. This data would be retrieved by calling each respective route with their IDs, and the API would obtain that data to fill out the template. Once the report was generated, the DOCX file was saved, and a PDF copy would be created. Subsequently, a separate unique GCS bucket would be generated, and these files would be stored there.\nFinally, a report would be created and stored in a \"Reports\" collection in our database, with its status updated to Complete. At this point, a user would see it appear in their Reports section of the web app, and they would be able to download the DOCX or PDF file at their leisure." 
					},
					]}
			/>
            <ProjectCard 
				project_name="Client Import via CSV" 
				company="Trava" 
				description="Imports clients using data from a csv file."
				images={ProjectTwoImages}
				sections={[
					{ 
						name: "Overview", 
						description: "The Client Import via CSV feature allowed tenants to upload a CSV file so they could quickly add new clients or update existing ones. They would download a template that listed names, emails, and domain info, and then fill it out with their clients' information. Once this was done, they would need to navigate to that section of our app, upload the file, and fix any errors, such as potentially incorrect formatting or missing required fields. This action would then send a request to our API to create all of these new tenants, check that they didn't already exist, and if they did, update that client's information."
					},
					{ 
						name: "Why was this feature important?", 
						description: "During my time at Trava, there was no way to mass upload many clients, which was a feature that many users requested due to its time-consuming nature. To upload more than one client, you would have to fill out an entire field, wait for it to upload, and then repeat the process. With the implementation of this new feature, users would simply need to compile all their clients' information into one CSV file and be able to create all of those tenants with a simple click of a button."
					},
					{ 
						name: "Import Process", 
						description: "Once a tenant downloaded the template and read through the PDF instructions, they could then proceed to fill out the CSV file with their client names, domains, emails, etc. When the file was initially uploaded, an initial validation check would be run to ensure all entries would append to the proper type once the creation process was undergone. For example, the NAICS code could only be specific values and would not accept any unknown numbers. To fix this, I implemented an error handling system that would display errors indicating what was missing/incorrect and on which line in the CSV file. \nOnce the CSV file was validated, the tenant could then submit the collection of client data entries to our API. During this secondary check, it would check to see if any of the submitted clients already existed and would also check if any entries present in the CSV were different from what we had on file. If both of these were true, it would return that client to the \"Updated Clients\" section. All other clients would be returned as \"New Clients\" as there was no existing client for those entries. \nThese two data fields would be returned and put into two tables. At this point, the user could review all the clients that they submitted in an easy-to-understand format to ensure that each of their entries was correct. Once they were happy with these results, they could then submit the clients to be created/updated, and they would appear in the \"Clients\" section of the web app."
					},
					]}
				/>
            <ProjectCard 
				project_name="Spotify Current Daylist" 
				company="Personal" 
				description="Displays my current Spotify daylist."
			/>
		</main>
	</GradientLayout>
</Layout>

<style>
	main {
		margin: auto;
		padding: 1rem;
		width: 800px;
		max-width: calc(100% - 2rem);
		color: #28323E;
		font-size: 20px;
		line-height: 1.6;
	}
	h1 {
		font-size: 2.5rem;
		font-weight: 500;
		line-height: 1;
		margin-bottom: 1em;
		margin-top: 1em;
	}
	.subheader {
		font-size: 1.25rem;
		font-weight: 100;
		line-height: 1;
		padding-bottom: 2rem;
	}
</style>
